#!/usr/local/bin/ruby
# Script to run LSRSv5 in batch mode
# It is spawned from cron
# It uses a control file generated by lsrs5_controller:lsrs_batch
# It uses a list of polygon numbers from a text file generated by lsrs_batch
# It constructs a call to the LSRS calculations for each polygon
# It reads in the original status file and updates that same status file  -- TODO - UPDATE STATUS FILE
# It writes its output to HTML and CSV files.
# call using 
#   cd /production/sites/sislsrs ; rails runner app/scripts/lsrs5_batch_cron.rb

@batchDir = "/production/sites/sislsrs/public/batch5/"

# check to see if a job can be processed
if Dir.glob(@batchDir + "pending/*.yml") == [] then exit end
if Dir.glob(@batchDir + "processing/*.yml") != [] then exit end

puts "running a job"

# set up the environment
redis = Redis.new

# get the control file
Dir.chdir(@batchDir + "pending/")
nextJob = Dir.glob("*.yml").sort[0]
@controlPathname = @batchDir + "processing/" + nextJob
FileUtils.mv(@batchDir + "pending/" + nextJob, @controlPathname)
@control = YAML.load_file(@controlPathname)

# parse contents of control file
@detailsRootURL = @control['DetailsRootURL']
outputXmlFilename = @control['OutputXmlFilename']
outputCsvFilename = @control['OutputCsvFilename']
outputDbfFilename = @control['OutputDbfFilename']
outputHtmlFilename = @control['OutputHtmlFilename']
outputDbfSummaryFilename = @control['OutputDbfSummaryFilename']
@statusFilename = @control['StatusFilename']
@statusURL = @control['StatusURL']
@outputURL = @control['OutputURL']
@frameworkName = @control['FrameworkName']
@cmpTable = @control['ComponentTable']
@fromPoly = @control['FromPoly']
@toPoly = @control['ToPoly']
@crop = @control['Crop']
@management = @control['Management']
@climateName = @control['ClimateTable']  ########## TODO: change from MySQL table row to Redis key name

# Get array of polygon identifiers from the text file that was generated by the lsrsbatch_controller
@slArray = File.new(@control['PolygonsFilename']).readlines.map {|line| line.chomp}

# set some names
@climateSourcePathname = "/production/data/climate/polygons/#{@climateName}.txt"
@normalsDumpPathname = @climateSourcePathname + "2normals.redisdump"
@indicesDumpPathname = @climateSourcePathname + "3indices.redisdump"
@normalsKey = "#{@frameworkName}:#{@climateName}:normals"
@indicesKey = "#{@frameworkName}/#{@climateName}:indices"

# check to see if climate data has been processed into indices
if not File.exist?(@climateSourcePathname) then puts "ERROR: Climate data file doesn't exist"; exit end
if not File.exist?(@normalsDumpPathname) then puts "NOTE: Climate data redisdump file doesn't exist" end
if not File.exist?(@indicesDumpPathname) then puts "NOTE: Climate indices redisdump file doesn't exist" end

# load or update climate data into Redis if necessary

# normals dump may be outdated (if source data was edited or updated on disk) or was never created
if File.exist?(@normalsDumpPathname) and File.mtime(@normalsDumpPathname) > File.mtime(@climateSourcePathname) then 
	# normals dump file is up to date
	if redis.expire(@normalsKey, 20000000) then
		puts "ttl for normals key was reset"
	else # key has expired, so reload from dump file
		redis.restore(@normalsKey,20000000,File.read(@normalsDumpPathname))
		puts "normals key was reloaded"
	end
else
	# normals redis key and redisdump as well as metadata file need to be created/updated
	puts "Refreshing redisdump of normals data"
	#Climate_load.monthlies(@climateSourcePathname, @normalsKey, @normalsDumpPathname)
	Climate_load.monthlies(@climateSourcePathname, @normalsKey)
	redis.expire(@normalsKey, 20000000)
end

# indices may be outdated or were never created
if File.exist?(@indicesDumpPathname) and File.mtime(@indicesDumpPathname) > File.mtime(@normalsDumpPathname) then
	# indices dump file is up to date
	if redis.expire(@indicesKey, 20000000) then
		puts "ttl for indices key was reset"
	else # key has expired, so reload from dump file
		redis.restore(@indicesKey,20000000,File.read(@indicesDumpPathname))
		puts "indices key was reloaded"
	end
else 
	# indices dump is outdated, so both redis key and redisdump need to be created/updated
	puts "Refreshing redisdump of indices"
	Climate_calc.monthlies(@normalsKey, @indicesKey, @indicesDumpPathname, redis)
	redis.expire(@indicesKey, 20000000)
end

# At this point redis has the latest climate data loaded, so calculate the LSRS ratings
@batch = AccessorsPolygonbatch.new
@batch.frameworkName = @control['FrameworkName']
@batch.cmpTableName = @control['ComponentTable']
@batch.fromPoly = @control['FromPoly'] # needed???
@batch.toPoly = @control['ToPoly'] # needed???
@batch.region = @control['Region'] # needed???
@batch.polygonsHash = Hash[File.new(@control['PolygonsFilename']).readlines.map {|line| line.chomp}.sort.uniq.zip] # Get polygon identifiers generated by the lsrsbatch_controller
@batch.crop = @control['Crop']
@batch.cropHash.store("CROP", @control['Crop']) # needed???
@batch.climateTableName = @control['ClimateTable']
@batch.climateIndicesKey = @control['ClimateTable'] + ":indices"
@batch.climateMetadata = JSON.parse(File.read("/production/data/climate/polygons/#{@control['ClimateTable']}.txt1metadata.json"), object_class: OpenStruct)
@batch.management = @control['Management']

# Initialize the HTML file
outputHtmlFile = File.open(@control['OutputHtmlFilename'], 'w') 
outputHtmlFile.puts '<html>'
outputHtmlFile.puts '<head>'
outputHtmlFile.puts '<title>LSRS results</title>'
outputHtmlFile.puts '</head>'
outputHtmlFile.puts '<body>'
outputHtmlFile.puts '<h2>Land Suitability Rating Information (LSRSv5)</h2>'
outputHtmlFile.puts '<table class="intro">'
outputHtmlFile.puts '<tr><td class="subheader">Database:</td><td class="Abbr">' + LsrsFramework.where(:WarehouseName => @frameworkName).first.Title_en + '</td></tr>'
outputHtmlFile.puts '<tr><td class="subheader">Climate:</td><td class="Abbr">' + @batch.climateMetadata.Title + '</td></tr>'
outputHtmlFile.puts '<tr><td class="subheader">Crop:</td><td class="Abbr">' + @crop + '</td></tr>'
outputHtmlFile.puts '<tr><td class="subheader">Management:</td><td class="Abbr">' + @management + '</td></tr>'
outputHtmlFile.puts '</table>'
outputHtmlFile.puts '<br/>'
outputHtmlFile.puts '<table>'

# Initialize the CSV file
outputCsvFile = File.open(@control['OutputCsvFilename'], 'w')
outputCsvFile.puts "POLY_ID,CMP_ID,POLY_RATING,CMP,PERCENT,CMP_CLASS,C_POINTS,C_CLASS,PROVINCE,SOIL_CODE,SOIL_NAME,S_POINTS,S_CLASS,L_POINTS,L_CLASS"

# populate the HTML and CSV files
i = 0 # initialize the status counter
# don't call Polygonbatch.calc_ratings(@batch) here because of the need to dump out different content for HTML vs CSV
params2 = {"FrameworkName"=>@batch.frameworkName, "Climate"=>@batch.climateTableName, "Crop"=>@batch.crop, "Management"=>@batch.management}
params4url = params2.to_s.delete('"{}> ').gsub(',','&')
for poly in @batch.polygonsHash.keys do
	params2["PolyId"] = poly
	@rating = AccessorsRating.new
	Validate.polygon(params2, @rating)
	Polygon.get_data(@rating.polygon, @rating.climateData, @rating.errors) if @rating.errors == []
	Polygon.get_ratings(@rating.crop, @rating.polygon, @rating.climateData.data, @rating.climate, @rating.errors) if @rating.errors == []
	Polygon.aggregate_ratings(@rating.polygon.components, @rating.climate, @rating.aggregate) if @rating.errors == []
	# populate HTML file
	polygonlink = "<a href=\"/lsrs5/polygon?PolyId=#{poly}&#{params4url}&Response=Details\">#{poly}</a>"
	if @rating.errors == [] then # output results
		outputHtmlFile.puts '<tr><td>' + polygonlink + ' = </td><td>' + @rating.aggregate + '</td></tr>'
	else # output error message
		outputHtmlFile.puts '<tr><td>' + polygonlink + ' = </td><td>' + @rating.errors.join("; ") + '</td></tr>'
	end
	# populate CSV file
	for cmp, index in @rating.polygon.components.each_with_index do
		csv = @rating.polygon.poly_id # POLY_ID
		csv += ',' + cmp.cmp_id # CMP_ID
		csv += ',' + @rating.aggregate # POLY_RATING
		csv += ',' + @rating.polygon.cmpData[index].cmp.to_s # CMP
		csv += ',' + @rating.polygon.cmpData[index].percent.to_s # PERCENT
		begin
			csv += ',' + [@rating.climate.suitability,cmp.soil.SuitabilityClass,cmp.landscape.SuitabilityClass].max.to_s # CMP_CLASS
		rescue ArgumentError
			csv += ',' + 'NR'
		end
		csv += ',' + @rating.climate.FinalRating.to_i.to_s # CLIMATE_POINTS
		csv += ',' + @rating.climate.suitability.to_s # CLIMATE_CLASS
		csv += ',' + cmp.soil.name.province # PROVINCE
		csv += ',' + cmp.soil.name.soil_code + cmp.soil.name.modifier # SOIL_CODE
		csv += ',' + cmp.soil.name.soilname # SOIL_NAME
		csv += ',' + cmp.soil.FinalSoilRating.to_s # SOIL_POINTS
		csv += ',' + cmp.soil.SuitabilityClass.to_s # SOIL_CLASS
		csv += ',' + cmp.landscape.FinalRating.to_s# LANDSCAPE_POINTS
		csv += ',' + cmp.landscape.SuitabilityClass.to_s # LANDSCAPE_CLASS
		outputCsvFile.puts csv
	end
	#update the status file regularly
	i += 1
	if i % 100 == 0
		percentComplete = ( (i + 1)/ @slArray.size.to_f * 100 ).round(2)
		xml = Wps1.CreateStatusXml(@statusURL, @outputURL, @cmpTable, @fromPoly, @toPoly, @crop, @management, @batch.climateTableName, "ProcessStarted", percentComplete)
		statusFile = File.open(@statusFilename, 'w')
		statusFile << xml.target!
		statusFile.close
	end
end

# close the HTML file
outputHtmlFile.puts "</table>"
outputHtmlFile.puts "</body>"
outputHtmlFile.puts "</html>"
outputHtmlFile.close

# close the CSV file
outputCsvFile.close

# update the status file
xml = Wps1.CreateStatusXml(@statusURL, @outputURL, @cmpTable, @fromPoly, @toPoly, @crop, @management, @batch.climateTableName, "ProcessSucceeded", 100)
statusFile = File.open(@statusFilename, 'w')
statusFile << xml.target!
statusFile.close
     
# delete the control file
FileUtils.rm(@controlPathname)
# update the log file
File.new(@batchDir + "lsrsbatchlog", "a").puts(Time.now.utc.strftime("%Y-%m-%dT%H:%M:%SZ") + " processing complete for " + nextJob)
